{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbQTPK45SAVFUgF6SVn2cQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":27,"metadata":{"id":"Rbih-GWb2z7g","executionInfo":{"status":"ok","timestamp":1763207678184,"user_tz":-330,"elapsed":17,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn  # for neural network layers\n","import torch.optim as optim  # for optimization algorithms\n","import torch.nn.functional as F  # for activation and loss functions\n","from torch.utils.data import DataLoader  # for batching and loading datasets\n","import torchvision.datasets as datasets  # for standard datasets like MNIST, CIFAR10, etc.\n","import torchvision.transforms as transforms  # for data transformations (normalization, augmentation)\n"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"],"metadata":{"id":"xxllmbCG9eae","executionInfo":{"status":"ok","timestamp":1763207678187,"user_tz":-330,"elapsed":1,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#hyper parameters\n","input_size=28\n","sequence_length=28\n","num_layers=2\n","hidden_size=256\n","num_classes=10\n","learning_rate=0.001\n","batch_size= 64\n","num_epochs= 2"],"metadata":{"id":"oheiFxTq-C7t","executionInfo":{"status":"ok","timestamp":1763207679383,"user_tz":-330,"elapsed":16,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class RNN(nn.Module):\n","  def __init__(self, input_size,hidden_size, num_layers,num_classes,sequence_length):\n","    super(RNN,self).__init__()\n","    self.hidden_size=hidden_size\n","    self.num_layers =num_layers\n","    self.sequence_length =sequence_length\n","    self.rnn= nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n","    self.fc=nn.Linear(hidden_size*sequence_length,num_classes)\n","    #time features\n","  def forward(self,x):\n","    h0=torch.zeros(self.num_layers, x.size(0),self.hidden_size).to(device)\n","    out,_=self.rnn(x,h0)\n","    out=out.reshape(out.shape[0],-1)\n","    out=self.fc(out)\n","    return out"],"metadata":{"id":"Xq9ygUvW_BDm","executionInfo":{"status":"ok","timestamp":1763204237664,"user_tz":-330,"elapsed":13,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Eb4zRWtZEgyr"}},{"cell_type":"code","source":["#data loading\n","train_dataset=datasets.MNIST(root='dataset/',train=True, transform=transforms.ToTensor(),download=True)\n","train_loader= DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n","test_dataset= datasets.MNIST(root='dataset/',train=False, transform=transforms.ToTensor(),download=True)\n","test_loader= DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)"],"metadata":{"id":"26NHaqO4EehI","executionInfo":{"status":"ok","timestamp":1763204241788,"user_tz":-330,"elapsed":2049,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ae6e27e-0508-41c4-8814-0635266ba1af"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 36.8MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 1.11MB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 9.87MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 6.41MB/s]\n"]}]},{"cell_type":"code","source":["#model\n","model=RNN( input_size,hidden_size, num_layers,num_classes,sequence_length).to(device)"],"metadata":{"id":"f6PFF85sNmv4","executionInfo":{"status":"ok","timestamp":1763204243526,"user_tz":-330,"elapsed":7,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#loss and optimizer\n","criterion=nn.CrossEntropyLoss()\n","optimizer=optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"bov1HjdjN_4L","executionInfo":{"status":"ok","timestamp":1763207692035,"user_tz":-330,"elapsed":10,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Move data & targets to device (CPU or GPU)\n","        data = data.to(device=device).squeeze(1)\n","        targets = targets.to(device=device)\n","\n","\n","        # Forward pass\n","        scores = model(data)\n","        loss = criterion(scores, targets)\n","\n","        # Backward pass\n","        optimizer.zero_grad()  # ✅ correct method is zero_grad(), not zerograd()\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","\n","\n","\n","\n"],"metadata":{"collapsed":true,"id":"9RFu9wWZhIqX","executionInfo":{"status":"ok","timestamp":1763204497940,"user_tz":-330,"elapsed":151828,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def check_accuracy(loader, model):\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # evaluation mode (disables dropout/batchnorm)\n","\n","    with torch.no_grad():  # no gradient computation needed\n","        for x, y in loader:\n","            x = x.to(device=device).squeeze(1)\n","            y = y.to(device=device)\n","\n","\n","            scores = model(x)\n","            _, predictions = scores.max(1)  # predicted class\n","\n","            num_correct += (predictions == y).sum().item()\n","            num_samples += predictions.size(0)\n","\n","    acc = float(num_correct) / float(num_samples)\n","    print(f'Got {num_correct}/{num_samples} with accuracy {acc*100:.2f}%')\n","\n","    model.train()  # back to training mode\n","    return acc\n","\n","\n"],"metadata":{"id":"N91VkDKuk9Yl","executionInfo":{"status":"ok","timestamp":1763204540949,"user_tz":-330,"elapsed":4,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["check_accuracy(train_loader,model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNwk2CM7otL4","executionInfo":{"status":"ok","timestamp":1763204573208,"user_tz":-330,"elapsed":29865,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"outputId":"e4782612-e498-495a-bcba-a4fc201a95e1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 58405/60000 with accuracy 97.34%\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9734166666666667"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["check_accuracy(test_loader,model)"],"metadata":{"id":"jM1CotHko0XD","executionInfo":{"status":"ok","timestamp":1763204603970,"user_tz":-330,"elapsed":30765,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"outputId":"0d4d9545-c3c1-4a9e-96b1-c72890838878","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 58405/60000 with accuracy 97.34%\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9734166666666667"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["class GruNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, sequence_length):\n","        super(GruNet, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.sequence_length = sequence_length\n","\n","        # GRU layer\n","        self.gru = nn.GRU(\n","            input_size=input_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,\n","        )\n","\n","        # Fully connected layer (using all timesteps)\n","        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","\n","        # Initial hidden state\n","        h0=torch.zeros(self.num_layers, x.size(0),self.hidden_size).to(device)\n","\n","        # GRU forward pass\n","        out, _ = self.gru(x, h0)     # out: [batch, seq_len, hidden_size]\n","\n","        # Flatten all time steps: [batch, seq_len * hidden]\n","        out = out.contiguous().view(batch_size, -1)\n","\n","        # Final classification layer\n","        out = self.fc(out)\n","\n","        return out\n"],"metadata":{"id":"2l84qHZjMNDe","executionInfo":{"status":"ok","timestamp":1763207790267,"user_tz":-330,"elapsed":14,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["model_gru=GruNet( input_size,hidden_size, num_layers,num_classes,sequence_length).to(device)"],"metadata":{"id":"I1PpskbYNw0_","executionInfo":{"status":"ok","timestamp":1763207792339,"user_tz":-330,"elapsed":14,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Move data & targets to device (CPU or GPU)\n","        data = data.to(device=device).squeeze(1)\n","        targets = targets.to(device=device)\n","\n","\n","        # Forward pass\n","        scores = model_gru(data)\n","        loss = criterion(scores, targets)\n","\n","        # Backward pass\n","        optimizer.zero_grad()  # ✅ correct method is zero_grad(), not zerograd()\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()"],"metadata":{"id":"vzKrSqWaN4En","executionInfo":{"status":"ok","timestamp":1763208308049,"user_tz":-330,"elapsed":420447,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["check_accuracy(test_loader,model_gru)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nYRqvTMOAA_","executionInfo":{"status":"ok","timestamp":1763205694453,"user_tz":-330,"elapsed":78952,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"outputId":"5fa01c66-fc79-4079-b6ca-df3bb13d4228"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 6903/60000 with accuracy 11.51%\n"]},{"output_type":"execute_result","data":{"text/plain":["0.11505"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["class LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","        return out\n"],"metadata":{"id":"GZF5ukAcOLnv","executionInfo":{"status":"ok","timestamp":1763209067614,"user_tz":-330,"elapsed":8,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["model_lstm=LSTM( input_size,hidden_size, num_layers,num_classes).to(device)"],"metadata":{"id":"IG65IpITOs7v","executionInfo":{"status":"ok","timestamp":1763209080799,"user_tz":-330,"elapsed":21,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Move data & targets to device (CPU or GPU)\n","        data = data.to(device=device).squeeze(1)\n","        targets = targets.to(device=device)\n","\n","\n","        # Forward pass\n","        scores = model_lstm(data)\n","        loss = criterion(scores, targets)\n","\n","        # Backward pass\n","        optimizer.zero_grad()  # ✅ correct method is zero_grad(), not zerograd()\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()"],"metadata":{"id":"A-OaM0C8QcWC","executionInfo":{"status":"ok","timestamp":1763209659094,"user_tz":-330,"elapsed":575801,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["check_accuracy(test_loader,model_lstm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROpfSF-XOxCW","executionInfo":{"status":"ok","timestamp":1763209750568,"user_tz":-330,"elapsed":91477,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"outputId":"bb8a7bdc-f0ad-42fc-ecfb-67898297e3f3"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Got 5958/60000 with accuracy 9.93%\n"]},{"output_type":"execute_result","data":{"text/plain":["0.0993"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        \"\"\"\n","        input_size  : number of features in input at each timestep\n","        hidden_size : number of features in LSTM hidden state\n","        num_layers  : number of stacked LSTM layers\n","        num_classes : output classes (for classification) or 1 for regression\n","        \"\"\"\n","        super(LSTMModel, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # LSTM layer\n","        self.lstm = nn.LSTM(\n","            input_size=input_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True  # batch dimension is first: [batch, seq_len, features]\n","        )\n","\n","        # Fully connected layer maps last hidden state to output\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: input tensor of shape [batch_size, seq_length, input_size]\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # Initialize hidden state and cell state with zeros\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n","\n","        # Pass through LSTM\n","        out, _ = self.lstm(x, (h0, c0))  # out: [batch, seq_length, hidden_size]\n","\n","        # Take the last time step's hidden state\n","        out = self.fc(out[:, -1, :])      # out: [batch, num_classes]\n","\n","        return out\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    # Hyperparameters\n","    input_size = 10    # features per timestep\n","    hidden_size = 32\n","    num_layers = 2\n","    num_classes = 3\n","    seq_length = 5\n","    batch_size = 8\n","\n","    # Create dummy input: [batch_size, seq_length, input_size]\n","    x = torch.randn(batch_size, seq_length, input_size)\n","\n","    # Create model\n","    model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n","\n","    # Forward pass\n","    output = model(x)\n","    print(\"Output shape:\", output.shape)  # should be [batch_size, num_classes]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3FwbR7xdgz-","executionInfo":{"status":"ok","timestamp":1763210687536,"user_tz":-330,"elapsed":44,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"outputId":"7472de06-f362-4ffd-c568-e954219658ab"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape: torch.Size([8, 3])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class GRUModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        \"\"\"\n","        input_size  : number of features in input at each timestep\n","        hidden_size : number of features in GRU hidden state\n","        num_layers  : number of stacked GRU layers\n","        num_classes : output classes (for classification) or 1 for regression\n","        \"\"\"\n","        super(GRUModel, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # GRU layer\n","        self.gru = nn.GRU(\n","            input_size=input_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True  # batch dimension is first: [batch, seq_len, features]\n","        )\n","\n","        # Fully connected layer maps last hidden state to output\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: input tensor of shape [batch_size, seq_length, input_size]\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # Initialize hidden state with zeros\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device=x.device)\n","\n","        # Pass through GRU\n","        out, _ = self.gru(x, h0)  # out: [batch, seq_length, hidden_size]\n","\n","        # Take the last time step's hidden state\n","        out = self.fc(out[:, -1, :])  # out: [batch, num_classes]\n","\n","        return out\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    # Hyperparameters\n","    input_size = 10\n","    hidden_size = 32\n","    num_layers = 2\n","    num_classes = 3\n","    seq_length = 5\n","    batch_size = 8\n","\n","    # Create dummy input: [batch_size, seq_length, input_size]\n","    x = torch.randn(batch_size, seq_length, input_size)\n","\n","    # Create model\n","    model = GRUModel(input_size, hidden_size, num_layers, num_classes)\n","\n","    # Forward pass\n","    output = model(x)\n","    print(\"Output shape:\", output.shape)  # should be [batch_size, num_classes]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFOAUftjdtLe","executionInfo":{"status":"ok","timestamp":1763210693992,"user_tz":-330,"elapsed":9,"user":{"displayName":"Eswaran Nanthaluxsan","userId":"07786617509000849002"}},"outputId":"1ffaa968-6f8f-4f72-fb33-d21fd921dd9e"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape: torch.Size([8, 3])\n"]}]},{"cell_type":"code","source":["import torch\n","\n","def compute_accuracy(predictions, targets):\n","    \"\"\"\n","    Compute accuracy for classification.\n","\n","    predictions: tensor of shape [batch_size, num_classes] (raw logits from model)\n","    targets: tensor of shape [batch_size] (ground truth labels)\n","    \"\"\"\n","    # Get predicted class (the one with highest score)\n","    _, predicted_classes = torch.max(predictions, dim=1)\n","\n","    # Compare with ground truth\n","    correct = (predicted_classes == targets).sum().item()\n","    total = targets.size(0)\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    batch_size = 8\n","    num_classes = 3\n","\n","    # Dummy predictions (logits)\n","    outputs = torch.randn(batch_size, num_classes)\n","    # Dummy ground truth labels\n","    labels = torch.randint(0, num_classes, (batch_size,))\n","\n","    acc = compute_accuracy(outputs, labels)\n","    print(\"Accuracy:\", acc)\n"],"metadata":{"id":"QWW0Qouhd8Fx"},"execution_count":null,"outputs":[]}]}